---
title: "Problem_Set_4"
author: "Amy Richardson"
date: "3/31/2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Initiate packages
```{r}
library(tidyverse)
library(ggplot2)
library(cluster)
library(factoextra)
library(dendextend)
library(dplyr)
library(tidyr)
library(psych)
library(pastecs)
library(car)
library(ggpubr)
library(pgirmess)
library(gridExtra)
```

##NYC Taxi Cab Data
```{r}
taxi_df <- read.csv("yellow_tripdata_2019-11.csv", header = TRUE)
zonei_df <- read.csv("taxi+_zone_lookup.csv", header = TRUE)

taxi_sub <- select(taxi_df, PULocationID, trip_distance, total_amount)

Loc_df <- merge(taxi_sub, zonei_df, by.x = "PULocationID", by.y = "LocationID")
Loc_df <- select(Loc_df, Zone, PULocationID, trip_distance, total_amount)
Loc_df <- filter(Loc_df, trip_distance > 0.1)
Loc_df <- filter(Loc_df, trip_distance < 100)
Loc_df<- filter(Loc_df, total_amount > 0 )

Loc_df <- inner_join(Loc_df,zonei_df)
Loc_df <- select(Loc_df, Zone, Borough, PULocationID, trip_distance, total_amount)
Loc_df <- filter(Loc_df, Borough != "EWR")
Loc_df <- filter(Loc_df, Borough != "Unknown")

Loc_df <- rename(Loc_df,
    Distance = trip_distance,
    Total_Cost = total_amount
    )

```

Standardize Trip Distance and Total Amount
```{r}
Loc_df$trip_distance <-scale(Loc_df$Distance)
Loc_df$total_amount <- scale(Loc_df$Total_Cost)

```

Histogram by Borough
```{r}
Loc_df %>%
  ggplot(aes(x = Distance, fill = Borough)) +
  geom_histogram () +
  facet_grid(Borough~., scales = "free") 
```


Describe by Borough
```{r}
describe(Loc_df$trip_distance)
by(Loc_df$trip_distance, Loc_df$Borough, stat.desc)
```

Randomly choose 50,000 trips - to reduce running time of cluster
```{r}
Loc_scale <- sample_n(Loc_df, 10000)
```


Can examine different number of groups
```{r}
set.seed(123)
k2 <- kmeans(Loc_scale [,4:5], 2, nstart = 25)
k3 <- kmeans(Loc_scale [,4:5], 3, nstart = 25)
k4 <- kmeans(Loc_scale [,4:5], 4, nstart = 25)
k5 <- kmeans(Loc_scale [,4:5], 5, nstart = 25)
k6 <- kmeans(Loc_scale [,4:5], 6, nstart = 25)
k7 <- kmeans(Loc_scale [,4:5], 7, nstart = 25)
k8 <- kmeans(Loc_scale [,4:5], 8, nstart = 25)
k9 <- kmeans(Loc_scale [,4:5], 9, nstart = 25)
k10 <- kmeans(Loc_scale [,4:5], 10, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 5")
p5 <- fviz_cluster(k6, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 6")
p6 <- fviz_cluster(k7, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 7")
p7 <- fviz_cluster(k8, geom = "point", Loc_scale [,4:5])+ ggtitle("k = 8")
p8 <- fviz_cluster(k9, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 9")
p9 <- fviz_cluster(k10, geom = "point", Loc_scale [,4:5]) + ggtitle("k = 10")


grid.arrange(p1, p2, p3, p4, nrow = 2)
grid.arrange(p5, p6, p7, p8, p9, nrow = 3)

```


Using Elbow Method to choose the optimum number of clusters [k]
```{r}
set.seed(123)

fviz_nbclust(Loc_scale [,4:5], kmeans, method = "wss")
```

Use Average Silhouette Method 
```{r}
fviz_nbclust(Loc_scale [,4:5], kmeans, method = "silhouette")
```

Extract Results
```{r}
set.seed(123)
final <- kmeans(Loc_scale [,4:5], 4, nstart = 25)
```


Plot Final Groups
```{r}
fviz_cluster(final, data = Loc_scale [,4:5])
```



Add Cluster numbers in new Dataframe
```{r}

k4_2 <- kmeans(Loc_scale [,4:5], 4)
kmeans_basic_table <- data.frame(k4_2$size, k4_2$centers)
kmeans_basic_df <- data.frame(Cluster = k4_2$cluster, Loc_scale)
head(kmeans_basic_df)

```

Find descriptive statistics for the 4 clusters
```{r}
Loc_scale %>%
  mutate(Cluster = final$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")
```


Example ggplot
```{r}
ggplot(data = kmeans_basic_df, aes(y = Cluster)) +
  geom_bar(aes(fill = Borough)) +
  ggtitle("Count of Clusters by Borough") +
  theme(plot.title = element_text(hjust = 0.5))
```






##END








